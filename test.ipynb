{"cells":[{"cell_type":"code","source":["!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.12.1+cu113.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.12.1+cu113.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"],"metadata":{"id":"5zSPqiPz7O4N","executionInfo":{"status":"ok","timestamp":1668574542347,"user_tz":-480,"elapsed":13311,"user":{"displayName":"zhao xiaohui","userId":"16787198146043111649"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3768,"status":"ok","timestamp":1668574546109,"user":{"displayName":"zhao xiaohui","userId":"16787198146043111649"},"user_tz":-480},"id":"9SOBcX8wxCDJ","outputId":"1a90ea1b-0c77-4ba3-92c6-a756b6c5873a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Do753O6Px100","executionInfo":{"status":"ok","timestamp":1668574546110,"user_tz":-480,"elapsed":16,"user":{"displayName":"zhao xiaohui","userId":"16787198146043111649"}}},"outputs":[],"source":["import os\n","os.chdir('/content/drive/My Drive/HST-GT/')\n","import sys\n","sys.path.append('/content/drive/My Drive/HST-GT/')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"-b0FgRbuw-93","executionInfo":{"status":"ok","timestamp":1668574547802,"user_tz":-480,"elapsed":1704,"user":{"displayName":"zhao xiaohui","userId":"16787198146043111649"}}},"outputs":[],"source":["\n","from Utils.utils_new import get_train_data,get_graph,get_y_time\n","import os\n","import torch\n","import numpy as np\n","from Model.HST_GT import HGT\n","from Utils.Metric_utils import *\n","lossfunction = torch.nn.MSELoss()\n","\n","def test(model_path,Recordpath):\n","    # split train test\n","    N_train = int(240 * 0.8)\n","    N_test = int(240 * 0.2)\n","\n","    train_range = list(range(N_train))\n","    test_range = list(range(N_train,N_train+N_test))\n","    import numpy as np\n","    y_all_t_all,y_wh_t_all,y_pack_t_all,y_sort_t_all = get_y_time()\n","    y_all_t_all = torch.from_numpy(np.array(y_all_t_all)).to('cpu').to(torch.float32)\n","    y_wh_t_all = torch.from_numpy(np.array(y_wh_t_all)).to('cpu').to(torch.float32)\n","    y_pack_t_all = torch.from_numpy(np.array(y_pack_t_all)).to('cpu').to(torch.float32)\n","    y_sort_t_all = torch.from_numpy(np.array(y_sort_t_all)).to('cpu').to(torch.float32)\n","\n","    train_data_wh,train_data_sort ,train_data_background_wh,train_data_background_sort\\\n","    ,y_all_t,y_wh_t ,y_sort_t ,y_pack_t \\\n","    ,wh_mask,sort_mask,wh_pack_mask,sort_pack_mask\\\n","    ,downstream_mask,context_mask\\\n","    ,graph = get_train_data()\n","\n","\n","    model =  torch.load(model_path)\n","\n","\n","    device = 'cuda:0'\n","\n","\n","    \n","\n","\n","    train_data_wh = torch.from_numpy(train_data_wh).to('cuda:0').to(torch.float32)\n","    train_data_sort = torch.from_numpy(train_data_sort).to('cuda:0').to(torch.float32)\n","    train_data_background_wh = torch.from_numpy(train_data_background_wh).to('cuda:0').to(torch.float32)\n","    train_data_background_sort = torch.from_numpy(train_data_background_sort).to('cuda:0').to(torch.float32)\n","\n","\n","\n","    wh_mask = wh_mask.to(device).to(torch.float32)\n","    sort_mask = sort_mask.to(device).to(torch.float32)\n","    mask_in = {\n","        'Node1':wh_mask,\n","        'Node2':sort_mask\n","    }\n","    wh_pack_mask = wh_pack_mask.to(device).to(torch.float32)\n","    sort_pack_mask = sort_pack_mask.to(device).to(torch.float32)\n","    mask_pack_in = {\n","        'Node1':wh_pack_mask,\n","        'Node2':sort_pack_mask\n","    }\n","    downmask_ins =torch.from_numpy(downstream_mask).to(device).to(torch.float32)\n","    cmask_ins=torch.from_numpy(context_mask).to(device).to(torch.float32)\n","    import numpy as np\n","    y_all_ts = [] \n","    y_wh_ts = []\n","    y_sort_ts = []\n","    y_pack_ts = []\n","\n","    for i in range(240):\n","        \n","        y_all_ts.append(torch.from_numpy(np.array(y_all_t[i])).to(device).to(torch.float32).view(-1,1))\n","        y_wh_ts.append(torch.from_numpy(np.array(y_wh_t[i])).to(device).to(torch.float32).view(-1,1))\n","        y_sort_ts.append(torch.from_numpy(np.array(y_sort_t[i])).to(device).to(torch.float32).view(-1,1))\n","        y_pack_ts.append(torch.from_numpy(np.array(y_pack_t[i])).to(device).to(torch.float32).view(-1,1))\n","\n","    print('------------Load Data Success------------')\n","\n","\n","\n","    import datetime\n","    model.eval()\n","    model.cuda()\n","    model.float()\n","    \n","\n","    x_dict = graph.x_dict\n","    edge_index_dict = graph.edge_index_dict\n","    starttime = datetime.datetime.now()\n","\n","    if_first = False\n","    loss_whs = 0\n","    loss_packs =0\n","    loss_sorts = 0\n","    loss_alls = 0\n","    losss = 0\n","    sn = 0\n","    firstcat = True\n","    outall = None\n","    outwh = None\n","    outpack = None\n","    outsort = None\n","    cmask = cmask_ins\n","    dmask = downmask_ins\n","    loss_whs = 0\n","    loss_packs =0\n","    loss_sorts = 0\n","    loss_alls = 0\n","    losss = 0\n","    sn = 0\n","    firstcat = True\n","    outall = None\n","    outwh = None\n","    outpack = None\n","    outsort = None\n","\n","    for t in test_range:\n","        print(t)\n","        \n","        test_temporal_data = {\n","            'Node1':train_data_wh[t].view(-1,4),\n","            'Node2':train_data_sort[t].view(-1,4)\n","        }\n","        test_back_data = {\n","            'Node1':train_data_background_wh[t].view(-1,3),\n","            'Node2':train_data_background_sort[t].view(-1,3)\n","        }\n","\n","\n","        \n","        y_wh_t = y_wh_ts[t]\n","        y_pack_t = y_pack_ts[t]\n","        y_sort_t = y_sort_ts[t]\n","        y_all_t = y_all_ts[t]\n","\n","    \n","        out = model(x_dict, edge_index_dict,test_temporal_data,test_back_data,mask_in,mask_pack_in,if_first,cmask,dmask)\n","\n","\n","        whout_norm = out['Node1']\n","        \n","\n","        packout_norm = out['pack']\n","        \n","\n","        sortout_norm = out['Node2']\n","        \n","\n","        allout_norm = out['Node1'] + out['pack'] + out['Node2']\n","        \n","\n","        if firstcat:\n","            firstcat = False\n","            outall = allout_norm.cpu().detach()\n","            outwh = whout_norm.cpu().detach()\n","            outpack = packout_norm.cpu().detach()\n","            outsort = sortout_norm.cpu().detach()\n","        else:\n","            outall = torch.cat((outall,allout_norm.cpu().detach()),dim=0)\n","            outwh = torch.cat((outwh,whout_norm.cpu().detach()),dim=0)\n","            outpack = torch.cat((outpack,packout_norm.cpu().detach()),dim=0)\n","            outsort = torch.cat((outsort,sortout_norm.cpu().detach()),dim=0)\n","        loss_wh = lossfunction(out['Node1'],y_wh_t)\n","        loss_sort = lossfunction(out['Node2'],y_sort_t)\n","        loss_pack = lossfunction(out['pack'],y_pack_t)\n","        loss_all = lossfunction(out['Node1']+out['Node2']+out['pack'],y_all_t)\n","        loss = loss_wh + loss_sort + loss_all + loss_pack\n","        \n","        \n","\n","        sn += len(y_all_t)\n","        tn = len(y_all_t)\n","\n","        loss_whs += float(loss_wh) * tn\n","        loss_packs += float(loss_pack) * tn\n","        loss_sorts += float(loss_sort) * tn\n","        loss_alls += float(loss_all) * tn\n","        losss += float(loss) * tn\n","\n","        \n","\n","    pres = {\n","        \"all\":outall,\n","        \"store\":outwh,\n","        \"pack\":outpack,\n","        \"sort\":outsort\n","    }\n","    yts =  {\n","        \"all\":y_all_t_all[312*N_train:],\n","        \"store\":y_wh_t_all[312*N_train:],\n","        \"pack\":y_pack_t_all[312*N_train:],\n","        \"sort\":y_sort_t_all[312*N_train:]\n","    }\n","    \n","    print(\"-------test loss--------\")\n","    \n","    print(\"loss_wh: {}, loss_pack: {}, loss_sort: {}, loss_all: {}, loss: {}\".format(loss_whs/sn,loss_packs/sn,loss_sorts/sn,loss_alls/sn,losss/sn))\n","    \n","    r = metric_all(pres,yts)\n","    print(\"-------test metric--------\")\n","    for i in r:\n","        print(i,r[i],end=' ')\n","    print()\n","    with open(Recordpath + \"test_record.txt\",'a+') as f:\n","        print(\"loss_wh: {}, loss_pack: {}, loss_sort: {}, loss_all: {}, loss: {}\".format(loss_whs/sn,loss_packs/sn,loss_sorts/sn,loss_alls/sn,losss/sn),file=f)\n","    with open(Recordpath + \"test_metric.txt\",\"a+\") as f:\n","        print(metric_all(pres,yts),file=f)\n","    return pres, yts\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rZxP0eELw-9-"},"outputs":[],"source":["pres,yts = test('Model_Save/model.pkl','Records/')"]},{"cell_type":"code","source":[],"metadata":{"id":"q0LCYqkgBsxq","executionInfo":{"status":"ok","timestamp":1668574578918,"user_tz":-480,"elapsed":6,"user":{"displayName":"zhao xiaohui","userId":"16787198146043111649"}}},"execution_count":5,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.7.11 ('torch')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"vscode":{"interpreter":{"hash":"06430a72881b56994481333f3ffe1c410952617f52895163945b00dc59d62dd0"}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}